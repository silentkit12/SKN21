{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e93c9500-6e1f-445a-a5e1-95e687853ae8",
   "metadata": {},
   "source": [
    "# Pytorch의 nn.Embedding\n",
    "- Pytorch의 Embedding Layer는 word2vec과 마찬가지로 word embedding vector를 찾는 **Lookup Table**이다.\n",
    "    - 단어의 **정수의 고유 index**가 입력으로 들어오면 Embedding Layer의 **그 index의 Vector**를 출력한다.\n",
    "    - 모델이 학습되는 동안 모델이 풀려는 문제에 맞는 값으로 Embedding Layer의 vector들이 업데이트 된다.\n",
    "    - Word2Vec의 embedding vector 학습을 nn.Embedding은 자신이 포함된 모델을 학습 하는 과정에서 한다고 생각하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936d8f7-a203-4452-978f-e2da81b7dafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d166e4e-4ced-4bc8-a188-12358670ad0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca59e731-381d-4a79-83c4-1fc20ba006e1",
   "metadata": {},
   "source": [
    "# 네이버 영화 댓글 감성분석(Sentiment Analysis)\n",
    "\n",
    "## 감성분석(Sentiment Analysis) 이란\n",
    "입력된 텍스트가 **긍적적인 글**인지 **부정적인**인지 또는 **중립적인** 글인지 분석하는 것을 감성(감정) 분석이라고 한다.   \n",
    "이를 통해 기업이 고객이 자신들의 기업 또는 제품에 대해 어떤 의견을 가지고 있는지 분석한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7034ada-08b9-4163-b18d-ce429aef275b",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader 생성\n",
    "\n",
    "## Korpora에서 Naver 영화 댓글 dataset 가져오기\n",
    "- https://ko-nlp.github.io/Korpora/ko-docs/corpuslist/nsmc.html\n",
    "- http://github.com/e9t/nsmc/\n",
    "    - input: 영화댓글\n",
    "    - output: 0(부정적댓글), 1(긍정적댓글)\n",
    "### API\n",
    "- **corpus 가져오기**\n",
    "    - `Korpora.load('nsmc')`\n",
    "- **text/label 조회**\n",
    "    - `corpus.get_all_texts()` : 전체 corpus의 text들을 tuple로 반환\n",
    "    - `corpus.get_all_labels()`: 전체 corpus의 label들을 list로 반환\n",
    "- **train/test set 나눠서 조회**\n",
    "    - `corpus.train`\n",
    "    - `corpus.test`\n",
    "    - `LabeledSentenceKorpusData` 객체에 text와 label들을 담아서 제공.\n",
    "        - `LabeledSentenceKorpusData.texts`: text들 tuple로 반환.\n",
    "        - `LabeledSentenceKorpusData.labels`: label들 list로 반환."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e2ea3-6123-4ebd-8e98-27b1db6406ed",
   "metadata": {},
   "source": [
    "## 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebdb0ac-eaaa-47aa-a0de-11d49e8a427b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b08d5-bfcd-4430-b4c0-44b19bbf4022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a23c0-06c5-49b7-b601-1ede1198b4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2e7e54a-548d-4bf3-81aa-357ab249f41a",
   "metadata": {},
   "source": [
    "## 토큰화\n",
    "1. 형태소 단위 token화\n",
    "    - konlpy로 token화 한 뒤 다시 한 문장으로 만든다.\n",
    "2. 1에서 처리한 corpus를 BPE 로 token화\n",
    "   \n",
    "### 전처리 함수\n",
    "\n",
    "#### 형태소 단위 분절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbb39b-9f49-4d29-a969-4839c01f430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    1. 영문 -> 소문자로 변환\n",
    "    2. 구두점 제거\n",
    "    3. 형태소 기반 토큰화\n",
    "    4. 형태소로 토큰화 한 뒤 다시 하나의 문자열로 묶어서 반환.\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f45e2f-f76a-4011-b963-d7feb214cc35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e658962-2fd6-4b1d-b4ef-a38de3ecc847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a25c93-7e26-4512-a0c0-56218fcda100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7cad7-23d9-4212-b07a-0e5da2ff73c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e519a68-d3a0-4481-bcf7-b121d8ba813f",
   "metadata": {},
   "source": [
    "### 토큰화\n",
    "- Subword 방식 토큰화 적용\n",
    "- Byte Pair Encoding 방식으로 huggingface tokenizer 사용\n",
    "    - BPE: 토큰을 글자 단위로 나눈뒤 가장 자주 등장하는 글자 쌍(byte paire)를 찾아 합친뒤 어휘사전에 추가한다.\n",
    "    - https://huggingface.co/docs/tokenizers/quicktour\n",
    "    - `pip install tokenizers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f162bdf-fac9-4468-a264-c656e4b3164d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b29e1-384a-44e8-ab19-e53f0c1303c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998d38b-e762-4fd5-b37f-8f8a2b6f5849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09f5c31d-633c-4a31-8f66-dff2ecf8e86a",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27280e-dfb7-4947-9192-777e6984286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NSMCDataset(Dataset):\n",
    "    def __init__(self, texts, labels, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        texts: list - 댓글 리스트. 리스트에 댓글들을 담아서 받는다. [\"댓글\", \"댓글\", ...]\n",
    "        labels: list - Label 리스트. (댓글의 긍부정 여부 - 긍정: 1, 부정: 0)\n",
    "        max_length: 개별 댓글의 token 개수. 모든 댓글의 토큰수를 max_length에 맞춘다.\n",
    "        tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    ###########################################################################################\n",
    "    # id로 구성된 개별 문장 token list를 받아서 패딩 추가 [20, 2, 1] => [20, 2, 1, 0, 0, 0, ..]\n",
    "    ############################################################################################\n",
    "    def __pad_token_sequences(self, token_sequences):\n",
    "        \"\"\"\n",
    "        token id로 구성된 개별 문서(댓글)의 token_id list를 받아서 max_length 길이에 맞추는 메소드\n",
    "        max_length 보다 토큰수가 적으면 [PAD] 토큰 추가, 많으면 max_length 크기로 줄인다.\n",
    "            ex) max_length=5 이고 pad토큰 id가 0이라면\n",
    "                [20, 2, 1] => [20, 2, 1, 0, 0, 0]\n",
    "                [20, 21, 30, 34, 60, 17, 21, 33] -> [20, 21, 30, 34, 60]\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        idx 번째 text와 label을 학습 가능한 type으로 변환해서 반환\n",
    "        Parameter\n",
    "            idx: int 조회할 index\n",
    "        Return\n",
    "            tuple: (torch.LongTensor, torch.FloatTensor) - 댓글 토큰_id 리스트, 정답 Label\n",
    "        \"\"\"\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515bb6f-703d-4277-b645-8869267f5297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f63e1-4ba8-4ccc-8c62-422b1f30b431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee963d58-0008-4fa6-b426-e3e332591f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5f00e-70fa-475b-8e2d-d06d120e3bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42b5f038-b32c-4e4e-82c8-956c7cbe0c4d",
   "metadata": {},
   "source": [
    "# 모델링\n",
    "- Embedding Layer를 이용해 Word Embedding Vector를 추출한다.\n",
    "- LSTM을 이용해 Feature 추출\n",
    "- Linear + Sigmoid로 댓글 긍정일 확률 출력\n",
    "  \n",
    "![outline](figures/rnn/RNN_outline.png)\n",
    "\n",
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac88afd6-5c8f-4ade-b930-86c9425e86e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9cbbd8-d8b4-4a51-ac7a-5765722f139e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af1a0171-371e-4cb5-9bd5-ad1e3c14480d",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7830d2b5-d5ed-4b53-a442-bebc83077aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae04a25a-c6dc-4833-883b-54972a16c171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe5b3d-8b2f-4164-9b97-29e6aadced5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d229e-9a99-4a28-9dfd-9582686ba052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bdd5885-8150-4529-ad3a-84931a8824c5",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a1bf6-d8eb-42d0-996e-f975e93888af",
   "metadata": {},
   "source": [
    "### Train/Test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46099bec-eee3-4cef-921b-ce9ee6cf0f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5eb3ea-78e8-4248-a8ce-d07a4c362d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de42da4-8991-4bcb-9ce9-18155459dec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c8853d0-b137-47bb-8f0d-fc4f05700cf2",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd806dda-5058-4c44-a3f4-28cadc8a90d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e18c2-17bf-4621-b630-b47e16c34bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6ec21-1d3c-48c2-b7c3-314daea6576c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32690441-482a-46b1-b91b-b85329d2141f",
   "metadata": {},
   "source": [
    "## 모델저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c16618-1517-4371-8e37-ae3cf03428b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d41e8-0715-4f50-aa37-11a8e142706a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3de7ed5-f7f6-4206-b16f-f8535a03405c",
   "metadata": {},
   "source": [
    "# 서비스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827bdaa3-008d-4a93-aee6-0877e829ef32",
   "metadata": {},
   "source": [
    "## 전처리 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2661a9-3964-4117-b273-e5d8bd4194b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "def text_preprocessing(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]+\", ' ', text)\n",
    "    return ' '.join(okt.morphs(text, stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315603df-159b-4317-9fb4-7897546b7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_token_sequences(token_sequences, max_length):\n",
    "    \"\"\"padding 처리 메소드.\"\"\"\n",
    "    pad_token = tokenizer.token_to_id('[PAD]')  \n",
    "    seq_length = len(token_sequences)           \n",
    "    result = None\n",
    "    if seq_length > max_length:                 \n",
    "        result = token_sequences[:max_length]\n",
    "    else:                                            \n",
    "        result = token_sequences + ([pad_token] * (max_length - seq_length))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73070a-0ee5-4f35-996c-b0d11ba08516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data_preprocessing(text_list):\n",
    "    \"\"\"\n",
    "    모델에 입력할 수있는 input data를 생성\n",
    "    Parameter:\n",
    "        text_list: list - 추론할 댓글리스트\n",
    "    Return\n",
    "        torch.LongTensor - 댓글 token_id tensor\n",
    "    \"\"\"\n",
    "   \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e19997-6b61-446f-ac72-376cd34ee495",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb00ab-60d0-45f2-bb16-505a5f5cc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = [\"아 진짜 재미없다.\", \"여기 식당 먹을만 해요\", \"이걸 영화라고 만들었냐?\", \"기대 안하고 봐서 그런지 괜찮은데.\", \"이걸 영화라고 만들었나?\", \"아! 뭐야 진짜.\", \"재미있는데.\", \"연기 짱 좋아. 한번 더 볼 의향도 있다.\", \"뭐 그럭저럭\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c330d-69ff-43fb-9ee9-ad1c6054f9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273ac02-81f3-4391-b802-f9dca1f8d032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0510a47-9189-4c2a-a6e9-33b04971f2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
