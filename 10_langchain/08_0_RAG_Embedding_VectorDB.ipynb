{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1311b7",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "![rag_embedding](figures/rag_embedding.png)\n",
    "\n",
    "- 분할된 텍스트를 벡터 표현(임베딩 벡터)으로 변환한다.\n",
    "- LangChain은 OpenAI, HuggingFace 등 다양한 임베딩 모델을 지원하며, 동일한 인터페이스로 사용할 수 있다.\n",
    "- [임베딩모델의 메서드](https://reference.langchain.com/python/langchain/embeddings/#langchain.embeddings.init_embeddings)\n",
    "\n",
    "    - **`embed_documents(texts: List[str])`**\n",
    "        - 여러 문서를 받아 벡터화(임베딩)한다.\n",
    "        - Context를 벡터화 할 때 사용한다.\n",
    "    - **`embed_query(text: str)`**\n",
    "        - 하나의 문자열(문서)을 받아 벡터화한다.\n",
    "        - Query를 벡터화 할 때 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff941301-56f5-4219-89e8-6b54d5afd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "        \"나는 고양이와 개 중 반려동물로 개를 키우고 싶습니다.\",\n",
    "        \"이 강아지 품종은 진도개 입니다. 국제 표준으로 중대형견으로 분류되며 다리가 길어 체고가 높은 편에 속합니다.\",\n",
    "        \"日本の市内バスの運賃は主に距離によって決まり、地域やバス会社によって異なる場合があります\",                 # 일본의 시내버스 요금은 주로 거리에 따라 결정되며, 지역 및 버스 회사에 따라 다를 수 있습니다.\n",
    "        \"Bus fares in the United States vary from city to city, but are generally around $2.90 for a regular bus.\", # 미국의 버스 요금은 도시마다 다르지만, 일반적으로 정기 버스의 경우 2.90달러 정도입니다.\n",
    "        \"광역버스 요금은 일반 3000원, 청소년은 1800원, 어린이 1500원 입니다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465811fa-32dd-44f3-96f9-c6193cb414ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "702aae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "model_name = \"text-embedding-3-large\" #textembedding-3-small\n",
    "e_mode11 = OpenAIEmbeddings(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17e85b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m30 packages\u001b[0m \u001b[2min 222ms\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 301ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 315ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentence-transformers\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d3f0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface Embedding 모델 -> hub: task - NLP > sentence-similarity\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "e_model1 = HuggingFaceEmbeddings(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8e8a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollama 제공 Embedding 모델 -> 검색에서 embedding 선택\n",
    "#명령 프롬프트에서 모델을 미리 다운 받아 두어야 함.\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "model_name = \"bge-m3\"\n",
    "e_model1 = OllamaEmbeddings(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9620fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_docs = e_model1.embed_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be25fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 5\n",
      "<class 'list'> 1024\n"
     ]
    }
   ],
   "source": [
    "print(type(embeded_docs), len(embeded_docs))\n",
    "print(type(embeded_docs[0]), len(embeded_docs[0])) #내가 사용하는 모델이 몇 차원으로 사용되는지 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24045261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09135649353265762,\n",
       " -0.21472853422164917,\n",
       " -0.06951115280389786,\n",
       " 0.4359855055809021,\n",
       " -0.2690112590789795,\n",
       " 0.01922779716551304,\n",
       " -0.38983696699142456,\n",
       " -0.10033570230007172,\n",
       " 0.16697907447814941,\n",
       " -0.025480929762125015]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_docs[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae98920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa7f8671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeded_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea5c8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 유사한 문서를 찾기\n",
    "# 유사도 체크를 위한 방법: 방향 기반-코사인 유사도, 거리기반-유클리디안(L2), 맨하탄(L1) 거리계산\n",
    "\n",
    "import numpy as np\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    \"\"\" \n",
    "    코사인 유사도 계산\n",
    "    -1~1 사이 값을 반환\n",
    "    -1 : 정 반대의 의미\n",
    "     0 : 관계 없음\n",
    "     1 : 완벽히 같은 의미\n",
    "    \"\"\"\n",
    "    v1 = np.array(vector1)\n",
    "    v2 = np.array(vector2)\n",
    "\n",
    "    return(v1@v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "\n",
    "\n",
    "# np.lingalg.norm(v1)\n",
    "# sqrt(sum(v1**2)) # 원소들의 제곱의 합이 제곱근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb1d117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"개와 고양이 중 뭘 더 좋아하나요?\" # 지문\n",
    "query = \"요즘 버스요금 얼마야?\"\n",
    "embeded_query=e_model1.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04de2749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,0.3221959232296952\n",
      "2,0.26469901025995196\n",
      "3,0.6230979335082734\n",
      "4,0.6962746739084417\n",
      "5,0.6815668174117862\n"
     ]
    }
   ],
   "source": [
    "for i, embedded_doc in enumerate(embeded_docs): # 각 문서들의 embedding\n",
    "    print(f\"{i+1},{cosine_similarity(embeded_query, embedded_doc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d02707-99d9-4d48-826f-ae446a405fc6",
   "metadata": {},
   "source": [
    "# 벡터 데이터베이스(Vector Database)\n",
    "\n",
    "![rag_vector_store](figures/rag_vector_store.png)\n",
    "\n",
    "- **벡터 데이터베이스란**\n",
    "-  벡터 데이터베이스는 데이터를 고차원 벡터(임베딩)로 변환하여 저장하고, 벡터 간의 유사도를 기반으로 검색과 관리를 수행하는 특수한 형태의 데이터베이스이다.\n",
    "\n",
    "- **주요 특징**\n",
    "  - 텍스트, 이미지, 오디오 등의 비정형 데이터를 수치 벡터로 변환하여 저장\n",
    "   - 코사인 유사도, 유클리드 거리 등을 이용한 벡터 간 유사도 계산을 통한 검색\n",
    "   - 근사 최근접 이웃(Approximate Nearest Neighbor, ANN) 알고리즘을 통한 빠른 검색을 지원.\n",
    "\n",
    "## 벡터 데이터베이스와 딥러닝\n",
    "- 벡터 데이터베이스는 딥러닝 기술의 발전과 깊은 관련이 있다.\n",
    "- 딥러닝 모델은 학습 과정에서 데이터의 특징을 추출하는 방법을 함께 학습한다. 충분한 데이터를 학습한 딥러닝 모델은 **데이터의 특성을 설명하는 특성 벡터(feature vector)를 효과적으로 생성**할 수 있다.\n",
    "- 이때 추출된 특성 벡터는 고차원 데이터(RAW Data)를 저차원 공간에서 표현한 **임베딩 벡터**다.\n",
    "    - > **임베딩**은 고차원 데이터를 저차원 공간으로 변환하여 표현하는 방법으로, 정보 손실을 최소화하면서 데이터 간의 의미 있는 관계를 벡터 공간에서 유지한다.\n",
    "- 딥러닝 모델로 추출한 데이터의 특징(feature vector)을 임베딩 공간에 배치하면, 비슷한 데이터는 가까이, 그렇지 않은 데이터는 멀리 배치된다.\n",
    "- 이러한 특성을 활용하면 임베딩 벡터 간의 거리를 계산해 유사한 데이터를 효과적으로 검색할 수 있다. 벡터 데이터베이스는 이러한 임베딩 벡터의 특성을 기반으로 개발되었다.\n",
    "- 딥러닝 기술의 발전과 폭넓은 활용으로 임베딩 데이터의 사용이 증가하면서, 이를 저장하고 관리하는 기능에 특화된 데이터베이스에 대한 수요도 증가해 다양한 벡터 데이터베이스가 등장했다.\n",
    "\n",
    "## LLM과 벡터 데이터베이스\n",
    "- ChatGPT(LLM)의 등장 이후 벡터 데이터베이스는 폭발적인 주목을 받았다.\n",
    "- 임베딩 벡터의 유사도를 기반으로 문서를 검색하는 RAG(Relevant Augmented Generation) 기술은 LLM의 환각(할루시네이션) 현상을 줄이고, LLM을 추가 학습하지 않고도 최신 정보를 효율적으로 활용할 수 있는 핵심 기법으로 자리 잡았다.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a65063-9482-4fdb-9ada-941eb08fb3b2",
   "metadata": {},
   "source": [
    "## 벡터 데이터베이스 종류\n",
    "![img](figures/vector_database.png)\n",
    "\n",
    "<<https://blog.det.life/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c>>\n",
    "\n",
    "### 주요 벡터 데이터베이스 종류\n",
    "- **Qdrant**\n",
    "    - Rust로 개발된 고성능 벡터 검색 엔진으로, 실시간 근사 최근접 이웃 검색을 제공한다.  \n",
    "    - 추천 시스템에 특화되어 있으며, 벡터 임베딩 저장과 유사도 쿼리를 효율적으로 수행한다.\n",
    "- **Pinecone**\n",
    "    - 클라우드 기반의 완전 관리형 벡터 데이터베이스 서비스로, 간단한 API를 통해 벡터 데이터를 관리할 수 있다.  \n",
    "    - 자동 확장성과 고가용성을 제공하며, 실시간 데이터 수집과 유사성 검색에 최적화되어 있다.\n",
    "    - 가장 쉽게 시작할 수 있는 관리형 서비스를 제공한다.\n",
    "- **Chroma**\n",
    "    - 벡터 임베딩을 효율적으로 저장하고 검색할 수 있는 오픈소스 데이터베이스로, AI 및 머신러닝 애플리케이션에 최적화되어 있다.\n",
    "    - 대규모 임베딩 저장에 최적화되어 있다.\n",
    "- **FAISS**\n",
    "    - Facebook AI에서 개발한 고성능 벡터 검색 라이브러리로, 고차원 벡터의 효율적인 유사성 검색을 위해 최적화되어 있다.\n",
    "    - GPU를 활용해 계산 성능을 높이며, 벡터 양자화 기술을 활용하여 메모리 사용을 최적화한다.\n",
    "    - 근사 최근접 이웃 검색(ANNS)에 최적화되어 있다.\n",
    "- **Milvus**\n",
    "    - 오픈소스 벡터 데이터베이스로, 대규모 벡터 데이터를 효율적으로 저장하고 검색할 수 있다.  \n",
    "    - 분산 아키텍처를 채택하여 확장성이 뛰어나며, IVF_PQ, DiskANN 등 다양한 인덱싱 알고리즘을 지원한다.\n",
    "    - 대규모 데이터셋 처리에 가장 적합한 솔루션이다.\n",
    "- **Weaviate**\n",
    "    - 오픈소스 벡터 데이터베이스로, 텍스트, 이미지, 오디오 등 다양한 비정형 데이터를 벡터로 저장하고 검색할 수 있다.  \n",
    "    - GraphQL API를 통해 접근 가능하며, 내장된 머신러닝 모듈을 통해 가장 강력한 의미론적 검색 기능을 제공한다.\n",
    "- **Elasticsearch**\n",
    "    - HNSW 알고리즘을 사용하여 벡터 검색을 구현하는 검색 엔진이다.\n",
    "    - 전통적인 검색 기능과 벡터 검색을 효과적으로 결합할 수 있어, 하이브리드 검색에 가장 적합하다.\n",
    "- **PGVector**\n",
    "    - PostgreSQL의 확장 모듈로, 벡터 데이터를 저장하고 유사성 검색을 수행할 수 있게 해준다.  \n",
    "    - SQL과 통합된 벡터 연산이 가능하며, L2 거리, 코사인 거리, 내적 등 다양한 거리 측정 방식을 지원한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3f6fe-c5e2-4c4f-9ef8-2cf5850f1bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1336f523-0b76-419c-8e46-fa96bdbcbdd6",
   "metadata": {},
   "source": [
    "# Langchain - Vector Store 연동 \n",
    "- Langchain은 다양한 벡터 데이터베이스와 연동할 수 있다.\n",
    "- 벡터 데이터베이스 마다 API가 다르기 때문에, Langchain을 사용하면 동일한 interface로 사용할 수 있다.\n",
    "\n",
    "## **VectorStore**\n",
    "- Langchain이 지원하는 모든 벡터 데이터베이스는 **VectorStore** 인터페이스를 구현한다.\n",
    "- 그래서 Langchain에서는 벡터 데이터베이스를 **Vector Store** 라고 한다.\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/\n",
    "\n",
    "### Vector Store 연결\n",
    "- Vector DB와 연결하는 메소드\n",
    "- `VectorStore.from_documents()`\n",
    "  - Document들을 insert 하면서 연결.\n",
    "  - Database가 있으면 연결, 없으면 생성하면서 연결한다.\n",
    "  - Parameter\n",
    "    - documents: insert할 문서들을 list[Document]로 전달.\n",
    "    - embedding model\n",
    "    - vector db에 연결하기 위한 설정들을 넣어준다.\n",
    "-`VectorStore()`\n",
    "  - vector db와 연결만 한다.\n",
    "  - Database가 있으면 연결, 없으면 생성하면서 연결한다.\n",
    "  - Parameter\n",
    "    - embedding model\n",
    "    - vector db에 연결하기 위한 설정들을 넣어준다.\n",
    "## InMemoryVectorStore\n",
    "- langchain에서 제공하는 메모리 기반 벡터 데이터베이스이다.\n",
    "- Data들을 Dictionary를 사용해 메모리에 저장하며, 검색 할 때 코사인 유사도(cosine similarity)를 계산하여 조회한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7fcddfb-0fd3-4cb8-a4f0-b72d1988d6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1092d6e3-2c41-426d-ac58-5f4ba1201ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "#Embedding Model 생성\n",
    "embedding_model = OpenAIEmbeddings(model = \"text-embedding-3-small\")\n",
    "#vectorStore 생성 -> Embedding 모델을 넣어서 생성\n",
    "vectorstore = InMemoryVectorStore(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afbc4641-857c-47c1-80ff-5f4c2651a4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "d1 = Document(id=1, page_content=\"Apple, Pear, Watermelon\", metadata={\"category\":\"fruit\"})\n",
    "d2 = Document(id=2, page_content=\"Pyton, Java, C++\", metadata={\"category\":\"it\"})\n",
    "d3 = Document(id=3, page_content=\"Football, Baseball, Basketball\", metadata={\"category\":\"sports\"})\n",
    "\n",
    "#VectorStore에 데이터를 넣기 - add_document() 리스트로 묶어 전달.\n",
    "vectorstore.add_documents(documents=[d1, d2, d3])\n",
    "\n",
    "#Vectorstore를 생성(연결) 하면서 문서들을 넣기(upsert)'\n",
    "#InMemoryVectorStore.from_documents(\n",
    "#              du)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "370e1af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Pyton, Java, C++\n",
      "2.Football, Baseball, Basketball\n",
      "3.Apple, Pear, Watermelon\n"
     ]
    }
   ],
   "source": [
    "# 검색 - 유사도 기반 검색\n",
    "query = \"SQL\"\n",
    "\n",
    "result = vectorstore.similarity_search(query=query, k=3) # k:유사도 높은 순서대로 문서 k를 반환 디폴트 4\n",
    "for i, r in enumerate(result):\n",
    "    print(f\"{i+1}.{r.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9828e2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Football, Baseball, Basketball 0.3175685714116114\n",
      "Pyton, Java, C++ 0.24514715608921359\n",
      "Apple, Pear, Watermelon 0.1684446334826007\n"
     ]
    }
   ],
   "source": [
    "query = \"SQL\"\n",
    "query = \"Iphone\"\n",
    "query = \"Rust\"\n",
    "query = \"Running\"\n",
    "\n",
    "result = vectorstore.similarity_search_with_score(query=query, k=3) #유사도 점수까지 반환\n",
    "#tuple - 검색한 Document, 유ㅜ사도 점수\n",
    "\n",
    "for doc, score in result:\n",
    "    print(doc.page_content,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9608e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0da7c8f-c1be-4ddf-a935-90b22eac1f11",
   "metadata": {},
   "source": [
    "# 실습\n",
    "1. text loading\n",
    "2. text split\n",
    "3. embedding + vector store(InMemoryVectorStore)에 저장\n",
    "4. query(질의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349be3ce-539e-4d18-bc2b-67e8100ebcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "path = \"data/olympic.txt\"\n",
    "# 문서 로드 + split\n",
    "loader = TextLoader(path, encoding='utf-8')\n",
    "# splitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600, chunk_overlap=50\n",
    ")\n",
    "docs = loader.load_and_split(splitter)\n",
    "docs = [doc for doc in docs if len(doc.page_content) >= 10] # 10 글자 이내면 제거\n",
    "\n",
    "# vectorstroe에 연결 + 저장\n",
    "## embedding model\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "## vectorSotore 생성\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "152a3ac6-6f56-41ea-9c60-6a982226eb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/olympic.txt'}, page_content='올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아 제전에서 영감을 얻어, 근대 올림픽을 부활시켰다. 이를 위해 쿠베르탱 남작은 1894년에 IOC를 창설했으며, 2년 뒤인 1896년에 그리스 아테네에서 제 1회 올림픽이 열렸다. 이때부터 IOC는 올림픽 운동의 감독 기구가 되었으며, 조직과 활동은 올림픽 헌장을 따른다. 오늘날 전 세계 대부분의 국가에서 올림픽 메달은 매우 큰 영예이며, 특히 올림픽 금메달리스트는 국가 영웅급의 대우를 받으며 스포츠 스타가 된다. 국가별로 올림픽 메달리스트들에게 지급하는 포상금도 크다.')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8d01f0-2fd7-4795-85a1-4ce9ea26a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의\n",
    "query = \"IOC는 어떤 기관인가요?\"\n",
    "result_docs = vectorstore.similarity_search_with_score(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a612f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>|||0.5370253350186073|||page_content='국제 올림픽 위원회\n",
      "올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 • 미디어 파트너를 맺기 • 선수, 직원, 심판, 모든 사람과 기관이 올림픽 헌장을 지키는 것을 말한다. 국제올림픽위원회(IOC)는 모든 올림픽 활동을 통솔하는 단체로서, 올림픽 개최 도시 선정, 계획 감독, 종목 변경, 스폰서 및 방송권 계약 체결 등의 권리가 있다. 올림픽 활동은 크게 세 가지로 구성된다.\n",
      "- 국제경기연맹(IF)은 국제적인 규모의 경기를 관리, 감독하는 기구이다. 예를 들어서 국제 축구 연맹(FIFA)는 축구를 주관하며, 국제 배구 연맹(FIVB)은 배구를 주관하는 기구이다. 올림픽에는 현재 35개의 국제경기연맹이 있고 각 종목을 대표한다. (이 중에는 올림픽 종목은 아니지만 IOC의 승인을 받은 연맹도 있다.)\n",
      "- 국가 올림픽 위원회(NOC)는 각국의 올림픽 활동을 감독하는 기구이다. 예를 들어서 대한 올림픽 위원회(KOC)는 대한민국의 국가 올림픽 위원회이다. 현재 IOC에 소속된 국가 올림픽 위원회는 205개이다.' metadata={'source': 'data/olympic.txt'}\n",
      ">>>|||0.46060731480140615|||page_content='각 올림픽 종목들은 IOC로부터 승인을 받은 국제경기연맹의 관리를 받는다. 35개의 연맹이 IOC에서 승인을 받았으며, 승인을 받았지만 현재 정식종목이 아닌 종목을 감독하는 연맹도 있다. IOC의 승인을 받았지만 올림픽 종목이 아닌 스포츠들은 올림픽 종목으로 고려되지는 않으나, 올림픽이 끝난 후 처음으로 열리는 IOC총회 때마다 정식종목이 되도록 신청을 할 수는 있다. IOC 총회 때 정식종목 선정은 총회에 참석중인 IOC위원들의 투표를 통해 이루어지며, 재적 위원 수의 과반수 이상 찬성표를 얻어야 정식종목으로 인정을 받는다. IOC의 승인을 받은 스포츠이나 찬성표를 받지 못해 정식종목이 되지 못한 스포츠로는 체스와 서핑과 같은 것이 있다.' metadata={'source': 'data/olympic.txt'}\n",
      ">>>|||0.44808929002099224|||page_content='- 올림픽 조직 위원회(OCOG)는 임시적인 조직으로 올림픽의 총체적인 것(개막식, 페막식 등)을 책임지기 위해 구성된 조직이다. 올림픽 조직 위원회는 올림픽이 끝나면 해산되며 최종보고서를 IOC에 제출한다.\n",
      "올림픽의 공식언어는 프랑스어와 영어와 개최국의 공용어이다. 모든 선언(예를 들어서 개막식 때 각국 소개를 할 때)들은 세 언어가 모두 나오거나 영어나 프랑스어 중에서 한 언어로만 말하기도 한다. 개최국의 공용어가 영어나 프랑스어가 아닐 때는 당연히 그 나라의 공용어도 함께 나온다.' metadata={'source': 'data/olympic.txt'}\n",
      ">>>|||0.4447600140503764|||page_content='국제 올림픽 위원회(이하 IOC로 지칭)는 몇몇 위원들이 한 행위에 대해서 비판을 받고 있다. 그 예로 IOC 위원장이었던 에이버리 브런디지와 후안 안토니오 사마란치가 대표적인 사람이다. 브런디지는 20년 넘게 IOC 위원장직을 맡았고 임기 중에 올림픽을 정치적으로 휘말려들지 않게 하기 위해 보호했다. 그러나 그는 남아프리카 공화국 대표단에게 아파르트헤이트와 관련된 이슈를 건드리고 반유대정책을 함으로써 비난을 받았다. 사마란치 위원장 시기 때는 족벌 정치와 부패로 비난받았다. 사마란치가 스페인에서 프랑코 정권에 협력했다는 것도 비판의 이유가 되었다.\n",
      "1998년에 몇몇 IOC위원들이 2002년 솔트레이크 시티 동계 올림픽 유치 과정에서 미국에게 미국을 올림픽 개최지로 뽑아달라는 뇌물청탁을 받았다는 것이 폭로되었다. 이에 IOC는 사퇴한 IOC위원 4명과 강제 퇴출된 6명에 대한 조사를 했다. 이 스캔들은 이후에 개최지 선정에서 이와 같은 불미스러운 일이 일어나지 않게 하기 위해서 IOC가 개혁에 착수하도록 하는 긍정적인 역할을 하기도 했다.' metadata={'source': 'data/olympic.txt'}\n",
      ">>>|||0.41135857848013907|||page_content='이 언행이 많은 IOC위원들이 시온에 대해 언짢게 생각하게 되고 토리노가 개최지로 선정되도록 도와주는 역할을 했을 가능성도 제기되고 있다.' metadata={'source': 'data/olympic.txt'}\n"
     ]
    }
   ],
   "source": [
    "for doc, score in result_docs:\n",
    "    print(\">>>\", score, doc, sep=\"|||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb586c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 + 검색한 결과 context로 LLM에게 질의\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template=\"\"\" instruction\n",
    "당신은 QA 전문 assistant입니다.\n",
    "질문에 대해 주어진 context를 기반으로 답하여 주세요.\n",
    "context에 질문과 관련된 내용이 없을 경우 '주어진 정보로는 답을 알 수 없습니다.' 라고 답을 하세요\n",
    "context에 없는 내용으로 답변을 만들지 마세요\n",
    "\n",
    "# context\n",
    "{context}\n",
    "\n",
    "# 질문\n",
    "{query}\n",
    "\n",
    "#Output indicator\n",
    "- 답변을 context 어느 부분을 참조하였는지 각주를 달아주세요.\n",
    "\n",
    "예)\n",
    "\n",
    "#답변: \n",
    "최종답변 내용\n",
    "\n",
    "#참조내용: \n",
    "context에서 참조한 내용\n",
    "\"\"\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain= prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4040994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VectorDB에서 조회한 결과 중 page_content 값만 추출 -> prompt 의 context 주입\n",
    "context = '\\n\\n'.join(doc[0].page_content for doc in result_docs)\n",
    "result = chain.invoke({\"query\":query, \"context\":context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cfccf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#답변:\n",
      "국제 올림픽 위원회(IOC)는 모든 올림픽 활동을 통솔하는 단체로, 올림픽 개최 도시 선정·계획 감독·종목 변경·스폰서 및 방송권 계약 체결 등의 권한을 가진 기관입니다. 또한 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 올림픽 조직 위원회(OCOG) 등과 연계하여 올림픽 활동을 관리·감독합니다.\n",
      "\n",
      "#참조내용:\n",
      "- \"국제올림픽위원회(IOC)는 모든 올림픽 활동을 통솔하는 단체로서, 올림픽 개최 도시 선정, 계획 감독, 종목 변경, 스폰서 및 방송권 계약 체결 등의 권리가 있다.\"  \n",
      "- \"올림픽 활동은 크게 세 가지로 구성된다.\"  \n",
      "- \"- 국제경기연맹(IF)은 국제적인 규모의 경기를 관리, 감독하는 기구이다.\"  \n",
      "- \"- 국가 올림픽 위원회(NOC)는 각국의 올림픽 활동을 감독하는 기구이다.\"  \n",
      "- \"- 올림픽 조직 위원회(OCOG)는 임시적인 조직으로 올림픽의 총체적인 것(개막식, 페막식 등)을 책임지기 위해 구성된 조직이다.\"\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c15ed2-e9d6-4361-9d9e-0dfaf650de41",
   "metadata": {},
   "source": [
    "## MMR(최대 한계 관련성-Maximal Marginal Relevance) 알고리즘 적용\n",
    "최대 한계 관련성(Maximal Marginal Relevance, MMR) 알고리즘은 정보 검색 및 요약에서 검색 결과의 **관련성**과 **다양성**을 동시에 고려하여 최적의 결과를 제공하는 방법이다. \n",
    "이 알고리즘은 사용자 쿼리와의 관련성을 최대화하면서도 중복 정보를 최소화하여 다양한 정보를 제공하는 것을 목표로 한다.\n",
    "\n",
    "1. **관련성과 다양성의 균형 조절**: MMR은 사용자 쿼리와 문서 간의 유사성 점수와 이미 선택된 문서들과의 다양성 점수를 조합하여 각 문서의 최종 점수를 계산한다. 이를 통해 관련성이 높으면서도 중복되지 않는 문서를 선택한다.\n",
    "\n",
    "2. **수학적 정의**\n",
    "   $$\n",
    "   \\text{MMR} = \\lambda \\cdot \\text{Sim}(d, Q) - (1 - \\lambda) \\cdot \\max_{d' \\in D'} \\text{Sim}(d, d')\n",
    "   $$\n",
    "\n",
    "   - $\\text{Sim}(d, Q)$: 문서 $d$와 쿼리 $\\text{Q}$ 사이의 유사성. (문서 유사성 계산)\n",
    "   - $\\max_{d' \\in D'} \\text{Sim}(d, d')$: 문서 $d$와 이미 선택된 문서 집합 $D'$ 중 가장 유사한 문서와의 유사성. (문서 다양성 계산)\n",
    "   - $\\lambda$: 유사성과 다양성의 중요도를 조절하는 매개변수(parameter)\n",
    "3. **적용 분야**: MMR은 정보 검색, 추천 시스템, 문서 요약 등에서 활용된다. 특히 LLM 검색에서 성능 향상이 입증되었다.\n",
    "\n",
    "### `vectorStore.max_marginal_relevance_search()` 메소드\n",
    "  - MMR 알고리즘을 적용한 검색을 수행한다.\n",
    "  - **파라미터**\n",
    "    - **query**: 사용자로부터 입력받은 검색 쿼리\n",
    "    - **k**: 최종적으로 선택할 문서의 수\n",
    "    - **fetch\\_k**: MMR 알고리즘 적용 시 고려할 상위 문서의 수\n",
    "    - **lambda_mult**: 쿼리와의 유사성과 선택된 문서 간의 다양성 사이의 균형을 조절하는 매개변수. $\\lambda = 1$이면 유사성만 고려하고, $\\lambda = 0$이면 다양성만을 최대화한다.\n",
    "    - **filter**: 검색 결과를 필터링할 조건을 지정한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f92a398d-f0f6-416f-aad8-4c97ced68992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국제 올림픽 위원회\n",
      "올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 • 미디어 파\n",
      "--------------------------------------------------\n",
      "이 언행이 많은 IOC위원들이 시온에 대해 언짢게 생각하게 되고 토리노가 개최지로 선정되도\n",
      "--------------------------------------------------\n",
      "1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑\n",
      "--------------------------------------------------\n",
      "2004년 10월과 11월에 IOC는 '올림픽 프로그램 위원회'(Olympic Progra\n",
      "--------------------------------------------------\n",
      "후보도시로 선택되면 그 도시들은 IOC에 보내는 후보도시에 관한 문서에 그들의 계획을 더욱\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"IOC는 어떤 기구입니까?\"\n",
    "\n",
    "mmr_result = vectorstore.max_marginal_relevance_search(\n",
    "    query = query,\n",
    "    k=5,\n",
    "    fetch_k=10,     # 다양성 계산을 위해 상위 몇 개의 문서를 볼지 결정.\n",
    "    lambda_mult=0.5 # 관련성, 다양성을 반반씩\n",
    ")\n",
    "\n",
    "for doc in mmr_result:\n",
    "    print(doc.page_content[:50])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b3c9c-8f56-48fd-a952-9f79f0b75f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab46f5a-14b4-4b0d-a6ea-4dd855a452c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
